{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# 01 - NHANES Data Sourcing Pipeline\n",
                "\n",
                "This notebook demonstrates the complete data pipeline for acquiring and processing NHANES testosterone data.\n",
                "\n",
                "## Overview\n",
                "\n",
                "The National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. We use NHANES data to train our free testosterone estimation models.\n",
                "\n",
                "**Data Files Used:**\n",
                "- **TST** - Testosterone (LBXTST in ng/dL)\n",
                "- **SHBG** - Sex Hormone Binding Globulin (LBXSHBG in nmol/L)\n",
                "- **BIOPRO** - Biochemistry Profile containing Albumin (LBXSAL in g/dL)\n",
                "\n",
                "**Survey Cycles:**\n",
                "- 2011-2012\n",
                "- 2013-2014\n",
                "- 2015-2016\n",
                "\n",
                "## Pipeline Steps\n",
                "\n",
                "1. **Download** - Fetch XPT files from CDC NHANES website\n",
                "2. **Parse** - Read XPT files into pandas DataFrames\n",
                "3. **Clean** - Merge, convert units, and remove outliers\n",
                "4. **Report** - Generate quality report for verification"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "setup-header",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "First, we import the necessary modules from our `freeT` package."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add parent directory to path for imports (if running from notebooks/)\n",
                "project_root = Path.cwd().parent\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "# Import our data pipeline functions\n",
                "from freeT.data import download_nhanes, read_xpt, clean_nhanes_data, generate_quality_report\n",
                "from freeT.utils import ng_dl_to_nmol_l, nmol_l_to_ng_dl\n",
                "\n",
                "print(\"Imports successful!\")\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "download-header",
            "metadata": {},
            "source": [
                "## Step 1: Download NHANES Data\n",
                "\n",
                "The `download_nhanes()` function downloads XPT files from the CDC website. It:\n",
                "- Creates the output directory structure automatically\n",
                "- Skips files that already exist\n",
                "- Handles download errors gracefully\n",
                "\n",
                "**Note:** This step requires an internet connection and may take a few minutes depending on connection speed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "download",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define output directory for raw data\n",
                "data_dir = project_root / \"data\" / \"raw\"\n",
                "\n",
                "# Download NHANES data for all cycles (2011-2016)\n",
                "print(\"Starting NHANES data download...\\n\")\n",
                "download_result = download_nhanes(\n",
                "    output_dir=str(data_dir),\n",
                "    cycles=[\"2011-2012\", \"2013-2014\", \"2015-2016\"],\n",
                "    verbose=True\n",
                ")\n",
                "\n",
                "print(f\"\\nDownload complete!\")\n",
                "print(f\"Files downloaded: {len(download_result['downloaded'])}\")\n",
                "print(f\"Files skipped (already exist): {len(download_result['skipped'])}\")\n",
                "print(f\"Files failed: {len(download_result['failed'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "parse-header",
            "metadata": {},
            "source": [
                "## Step 2: Parse XPT Files\n",
                "\n",
                "The `read_xpt()` function reads SAS transport format files into pandas DataFrames.\n",
                "\n",
                "Let's load data from one cycle (2015-2016) as an example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "parse",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define paths to data files for 2015-2016 cycle\n",
                "cycle_dir = data_dir / \"2015_2016\"\n",
                "\n",
                "tst_path = cycle_dir / \"TST_I.XPT\"\n",
                "shbg_path = cycle_dir / \"SHBG_I.XPT\"\n",
                "alb_path = cycle_dir / \"BIOPRO_I.XPT\"\n",
                "\n",
                "# Read the XPT files\n",
                "print(\"Reading XPT files...\")\n",
                "tst_df = read_xpt(tst_path)\n",
                "shbg_df = read_xpt(shbg_path)\n",
                "alb_df = read_xpt(alb_path)\n",
                "\n",
                "print(f\"\\nTST data: {len(tst_df)} records, {len(tst_df.columns)} columns\")\n",
                "print(f\"SHBG data: {len(shbg_df)} records, {len(shbg_df.columns)} columns\")\n",
                "print(f\"ALB data: {len(alb_df)} records, {len(alb_df.columns)} columns\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "explore-data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview the testosterone data\n",
                "print(\"Testosterone data (TST) - Key columns:\")\n",
                "print(tst_df[['SEQN', 'LBXTST']].head(10))\n",
                "print(\"\\nLBXTST = Total testosterone in ng/dL\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "explore-shbg",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview the SHBG data\n",
                "print(\"SHBG data - Key columns:\")\n",
                "print(shbg_df[['SEQN', 'LBXSHBG']].head(10))\n",
                "print(\"\\nLBXSHBG = SHBG in nmol/L\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "explore-alb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview the albumin data (from biochemistry profile)\n",
                "print(\"Biochemistry Profile - Albumin column:\")\n",
                "print(alb_df[['SEQN', 'LBXSAL']].head(10))\n",
                "print(\"\\nLBXSAL = Serum albumin in g/dL\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "clean-header",
            "metadata": {},
            "source": [
                "## Step 3: Clean and Merge Data\n",
                "\n",
                "The `clean_nhanes_data()` function:\n",
                "1. **Merges** datasets on SEQN (participant ID)\n",
                "2. **Converts units** to standardized SI units:\n",
                "   - Testosterone: ng/dL → nmol/L (multiply by 0.0347)\n",
                "   - Albumin: g/dL → g/L (multiply by 10)\n",
                "   - SHBG: Already in nmol/L (no conversion)\n",
                "3. **Removes outliers** based on physiological limits:\n",
                "   - TT < 0.5 nmol/L (unreliably low)\n",
                "   - SHBG > 250 nmol/L (abnormally high)\n",
                "   - Albumin < 30 g/L (severe hypoalbuminemia)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clean",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean and merge the data for 2015-2016 cycle\n",
                "print(\"Cleaning 2015-2016 cycle data...\\n\")\n",
                "clean_df = clean_nhanes_data(tst_df, shbg_df, alb_df, verbose=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clean-preview",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview the cleaned data\n",
                "print(\"\\nCleaned data preview:\")\n",
                "print(clean_df.head(10))\n",
                "\n",
                "print(\"\\nColumn descriptions:\")\n",
                "print(\"- seqn: Participant ID\")\n",
                "print(\"- tt_nmoll: Total testosterone (nmol/L)\")\n",
                "print(\"- shbg_nmoll: SHBG (nmol/L)\")\n",
                "print(\"- alb_gl: Albumin (g/L)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clean-stats",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Basic statistics of the cleaned data\n",
                "print(\"Descriptive Statistics:\")\n",
                "print(clean_df[['tt_nmoll', 'shbg_nmoll', 'alb_gl']].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "combine-header",
            "metadata": {},
            "source": [
                "### Combining Multiple Cycles\n",
                "\n",
                "For training, we typically want to combine data from all available cycles to maximize sample size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "combine-cycles",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Define file mappings for each cycle\n",
                "cycles = {\n",
                "    \"2011-2012\": {\"TST\": \"TST_G.XPT\", \"SHBG\": \"SHBG_G.XPT\", \"ALB\": \"BIOPRO_G.XPT\"},\n",
                "    \"2013-2014\": {\"TST\": \"TST_H.XPT\", \"SHBG\": \"SHBG_H.XPT\", \"ALB\": \"BIOPRO_H.XPT\"},\n",
                "    \"2015-2016\": {\"TST\": \"TST_I.XPT\", \"SHBG\": \"SHBG_I.XPT\", \"ALB\": \"BIOPRO_I.XPT\"},\n",
                "}\n",
                "\n",
                "all_clean_dfs = []\n",
                "\n",
                "for cycle, files in cycles.items():\n",
                "    cycle_folder = cycle.replace(\"-\", \"_\")\n",
                "    cycle_path = data_dir / cycle_folder\n",
                "    \n",
                "    try:\n",
                "        print(f\"\\n{'='*50}\")\n",
                "        print(f\"Processing cycle: {cycle}\")\n",
                "        print(f\"{'='*50}\")\n",
                "        \n",
                "        # Read files\n",
                "        tst = read_xpt(cycle_path / files[\"TST\"])\n",
                "        shbg = read_xpt(cycle_path / files[\"SHBG\"])\n",
                "        alb = read_xpt(cycle_path / files[\"ALB\"])\n",
                "        \n",
                "        # Clean and merge\n",
                "        clean = clean_nhanes_data(tst, shbg, alb, verbose=True)\n",
                "        clean['cycle'] = cycle  # Add cycle identifier\n",
                "        \n",
                "        all_clean_dfs.append(clean)\n",
                "        \n",
                "    except FileNotFoundError as e:\n",
                "        print(f\"  [SKIP] Cycle {cycle}: {e}\")\n",
                "\n",
                "# Combine all cycles\n",
                "if all_clean_dfs:\n",
                "    combined_df = pd.concat(all_clean_dfs, ignore_index=True)\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"COMBINED DATASET: {len(combined_df)} total records\")\n",
                "    print(f\"{'='*50}\")\n",
                "else:\n",
                "    print(\"No data available - please run download step first.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "combined-summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary by cycle\n",
                "if 'combined_df' in dir() and combined_df is not None:\n",
                "    print(\"Records per cycle:\")\n",
                "    print(combined_df['cycle'].value_counts().sort_index())\n",
                "    \n",
                "    print(\"\\nOverall statistics:\")\n",
                "    print(combined_df[['tt_nmoll', 'shbg_nmoll', 'alb_gl']].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "report-header",
            "metadata": {},
            "source": [
                "## Step 4: Generate Quality Report\n",
                "\n",
                "The `generate_quality_report()` function creates a comprehensive quality report including:\n",
                "- Total record count\n",
                "- Mean and standard deviation for each variable\n",
                "- Min/max values\n",
                "- Missing value counts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "report",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate quality report\n",
                "reports_dir = project_root / \"reports\"\n",
                "report_path = reports_dir / \"data_quality_report.txt\"\n",
                "\n",
                "if 'combined_df' in dir() and combined_df is not None:\n",
                "    # Use combined data for report (excluding the 'cycle' column for analysis)\n",
                "    analysis_df = combined_df.drop(columns=['cycle'])\n",
                "    report = generate_quality_report(analysis_df, str(report_path))\n",
                "    \n",
                "    print(f\"Quality report saved to: {report_path}\")\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"REPORT SUMMARY\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"Total records: {report['record_count']}\")\n",
                "    print(\"\\nStatistics:\")\n",
                "    for col, stats in report['statistics'].items():\n",
                "        print(f\"  {col}: mean={stats['mean']:.2f}, SD={stats['sd']:.2f}\")\n",
                "else:\n",
                "    print(\"No data available for report - please run previous steps first.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-report",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the full report file\n",
                "if report_path.exists():\n",
                "    print(\"Full report contents:\")\n",
                "    print(\"\\n\" + report_path.read_text())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save-header",
            "metadata": {},
            "source": [
                "## Save Processed Data\n",
                "\n",
                "Finally, we save the cleaned and combined dataset for use in subsequent notebooks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save processed data\n",
                "processed_dir = project_root / \"data\" / \"processed\"\n",
                "processed_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "if 'combined_df' in dir() and combined_df is not None:\n",
                "    output_path = processed_dir / \"nhanes_combined.csv\"\n",
                "    combined_df.to_csv(output_path, index=False)\n",
                "    print(f\"Processed data saved to: {output_path}\")\n",
                "    print(f\"Total records: {len(combined_df)}\")\n",
                "else:\n",
                "    print(\"No data to save - please run previous steps first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook demonstrated the complete NHANES data pipeline:\n",
                "\n",
                "1. **Download** - `download_nhanes()` fetches XPT files from CDC\n",
                "2. **Parse** - `read_xpt()` reads SAS transport format files\n",
                "3. **Clean** - `clean_nhanes_data()` merges, converts units, removes outliers\n",
                "4. **Report** - `generate_quality_report()` creates verification report\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- **Notebook 02** - Solver Comparison: Compare Vermeulen, Södergård, and Zakharov methods\n",
                "- **Notebook 03** - Model Training: Train ML models on this data\n",
                "- **Notebook 04** - Evaluation: Validate model performance\n",
                "\n",
                "### Key Variables\n",
                "\n",
                "| Variable | Unit | Description |\n",
                "|----------|------|-------------|\n",
                "| tt_nmoll | nmol/L | Total testosterone |\n",
                "| shbg_nmoll | nmol/L | Sex Hormone Binding Globulin |\n",
                "| alb_gl | g/L | Serum albumin |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}