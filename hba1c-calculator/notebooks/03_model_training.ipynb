{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03: Model Training - ML Models for HbA1c Estimation\n",
                "\n",
                "This notebook demonstrates the complete ML training workflow for HbA1c estimation:\n",
                "\n",
                "1. **Loading** cleaned NHANES data from previous notebooks\n",
                "2. **Feature Engineering** using raw biomarkers and mechanistic estimators\n",
                "3. **Stratified Splitting** to balance HbA1c clinical ranges\n",
                "4. **Training** Ridge, Random Forest, and LightGBM models\n",
                "5. **Cross-Validation** for robust performance estimation\n",
                "6. **Model Comparison** and saving best model\n",
                "\n",
                "---\n",
                "\n",
                "## Background\n",
                "\n",
                "We use a hybrid approach that combines:\n",
                "- Raw biomarker features (FPG, TG, HDL, age, hemoglobin, MCV)\n",
                "- Ratio features (TG/HDL, FPG-age interaction)\n",
                "- Mechanistic estimator predictions (ADAG, kinetic, regression)\n",
                "\n",
                "This allows ML models to learn refinements on top of established clinical relationships."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard library imports\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add parent directory to path for imports\n",
                "sys.path.insert(0, str(Path.cwd().parent))\n",
                "\n",
                "# Third-party imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.linear_model import Ridge\n",
                "\n",
                "# Local imports\n",
                "from hba1cE.train import (\n",
                "    create_features,\n",
                "    stratified_split,\n",
                "    train_ridge,\n",
                "    train_random_forest,\n",
                "    train_lightgbm,\n",
                "    cross_validate_model,\n",
                "    save_model,\n",
                ")\n",
                "\n",
                "# Configure matplotlib\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "print(\"Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 1: Load Cleaned Data\n",
                "\n",
                "Load the cleaned NHANES glycemic data generated in Notebook 01."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load cleaned data\n",
                "DATA_DIR = Path.cwd().parent / \"data\"\n",
                "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
                "\n",
                "df = pd.read_csv(PROCESSED_DIR / \"nhanes_glycemic_cleaned.csv\")\n",
                "\n",
                "print(f\"Loaded dataset shape: {df.shape}\")\n",
                "print(f\"\\nColumns: {list(df.columns)}\")\n",
                "print(f\"\\nHbA1c range: {df['hba1c_percent'].min():.1f}% - {df['hba1c_percent'].max():.1f}%\")\n",
                "print(f\"\\nFirst 5 rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 2: Feature Engineering\n",
                "\n",
                "Create the feature matrix including:\n",
                "- Raw biomarker features\n",
                "- Ratio features  \n",
                "- Mechanistic estimator predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create features\n",
                "X, feature_names = create_features(df)\n",
                "\n",
                "print(f\"Feature matrix shape: {X.shape}\")\n",
                "print(f\"\\nFeatures ({len(feature_names)} total):\")\n",
                "for i, name in enumerate(feature_names):\n",
                "    print(f\"  {i+1}. {name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show feature statistics\n",
                "feature_df = pd.DataFrame(X, columns=feature_names)\n",
                "print(\"\\nFeature Statistics:\")\n",
                "feature_df.describe().round(2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 3: Stratified Train/Test Split\n",
                "\n",
                "Split data while maintaining balanced representation across HbA1c clinical ranges:\n",
                "- <5.7% (normal)\n",
                "- 5.7-6.4% (prediabetes)\n",
                "- 6.5-8% (mild diabetes)\n",
                "- 8-10% (moderate diabetes)\n",
                "- >10% (severe diabetes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Stratified split\n",
                "X_train, X_test, y_train, y_test = stratified_split(df, test_size=0.3, random_state=42)\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
                "print(f\"Test set:     {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
                "\n",
                "# Show HbA1c distribution in train/test\n",
                "print(f\"\\nHbA1c distribution:\")\n",
                "print(f\"  Train - mean: {y_train.mean():.2f}%, std: {y_train.std():.2f}%\")\n",
                "print(f\"  Test  - mean: {y_test.mean():.2f}%, std: {y_test.std():.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 4: Train Models\n",
                "\n",
                "Train three different models:\n",
                "1. **Ridge Regression** - Linear baseline with L2 regularization\n",
                "2. **Random Forest** - Ensemble of decision trees for nonlinear patterns\n",
                "3. **LightGBM** - Gradient boosting for best performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create validation set for LightGBM early stopping\n",
                "# Use 20% of training data for validation\n",
                "val_size = int(0.2 * len(X_train))\n",
                "X_val = X_train[:val_size]\n",
                "y_val = y_train[:val_size]\n",
                "X_train_lgb = X_train[val_size:]\n",
                "y_train_lgb = y_train[val_size:]\n",
                "\n",
                "print(f\"LightGBM validation set: {len(y_val)} samples\")\n",
                "print(f\"LightGBM training set: {len(y_train_lgb)} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Ridge Regression\n",
                "print(\"Training Ridge Regression...\")\n",
                "ridge_model = train_ridge(X_train, y_train, alpha=1.0)\n",
                "print(f\"  Coefficients: {len(ridge_model.coef_)}\")\n",
                "print(f\"  Intercept: {ridge_model.intercept_:.4f}\")\n",
                "print(\"  Done!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Random Forest\n",
                "print(\"Training Random Forest (200 trees)...\")\n",
                "rf_model = train_random_forest(X_train, y_train, n_estimators=200)\n",
                "print(f\"  Trees: {rf_model.n_estimators}\")\n",
                "print(\"  Done!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train LightGBM\n",
                "print(\"Training LightGBM with early stopping...\")\n",
                "lgb_model = train_lightgbm(\n",
                "    X_train_lgb, y_train_lgb,\n",
                "    X_val, y_val,\n",
                "    n_estimators=1000,\n",
                "    early_stopping_rounds=20\n",
                ")\n",
                "print(f\"  Best iteration: {lgb_model.best_iteration_}\")\n",
                "print(\"  Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 5: Cross-Validation\n",
                "\n",
                "Evaluate each model using 10-fold cross-validation for robust performance estimation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-validate all models\n",
                "print(\"Running 10-fold cross-validation...\\n\")\n",
                "\n",
                "# Ridge CV\n",
                "print(\"Ridge Regression:\")\n",
                "ridge_cv = cross_validate_model(Ridge(alpha=1.0), X_train, y_train, n_splits=10)\n",
                "print(f\"  RMSE: {ridge_cv['RMSE_mean']:.4f} ± {ridge_cv['RMSE_std']:.4f}\")\n",
                "print(f\"  MAE:  {ridge_cv['MAE_mean']:.4f} ± {ridge_cv['MAE_std']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Random Forest CV\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "print(\"Random Forest:\")\n",
                "rf_cv = cross_validate_model(\n",
                "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
                "    X_train, y_train, n_splits=10\n",
                ")\n",
                "print(f\"  RMSE: {rf_cv['RMSE_mean']:.4f} ± {rf_cv['RMSE_std']:.4f}\")\n",
                "print(f\"  MAE:  {rf_cv['MAE_mean']:.4f} ± {rf_cv['MAE_std']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LightGBM CV (using simpler config for CV)\n",
                "from lightgbm import LGBMRegressor\n",
                "\n",
                "print(\"LightGBM:\")\n",
                "lgb_cv = cross_validate_model(\n",
                "    LGBMRegressor(n_estimators=100, random_state=42, verbose=-1),\n",
                "    X_train, y_train, n_splits=10\n",
                ")\n",
                "print(f\"  RMSE: {lgb_cv['RMSE_mean']:.4f} ± {lgb_cv['RMSE_std']:.4f}\")\n",
                "print(f\"  MAE:  {lgb_cv['MAE_mean']:.4f} ± {lgb_cv['MAE_std']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 6: Results Comparison\n",
                "\n",
                "Compare all models in a summary table and visualize results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison table\n",
                "results_df = pd.DataFrame({\n",
                "    'Model': ['Ridge Regression', 'Random Forest', 'LightGBM'],\n",
                "    'RMSE_mean': [ridge_cv['RMSE_mean'], rf_cv['RMSE_mean'], lgb_cv['RMSE_mean']],\n",
                "    'RMSE_std': [ridge_cv['RMSE_std'], rf_cv['RMSE_std'], lgb_cv['RMSE_std']],\n",
                "    'MAE_mean': [ridge_cv['MAE_mean'], rf_cv['MAE_mean'], lgb_cv['MAE_mean']],\n",
                "    'MAE_std': [ridge_cv['MAE_std'], rf_cv['MAE_std'], lgb_cv['MAE_std']],\n",
                "})\n",
                "\n",
                "# Add formatted columns\n",
                "results_df['RMSE'] = results_df.apply(\n",
                "    lambda r: f\"{r['RMSE_mean']:.4f} ± {r['RMSE_std']:.4f}\", axis=1\n",
                ")\n",
                "results_df['MAE'] = results_df.apply(\n",
                "    lambda r: f\"{r['MAE_mean']:.4f} ± {r['MAE_std']:.4f}\", axis=1\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"CROSS-VALIDATION RESULTS COMPARISON\")\n",
                "print(\"=\"*60)\n",
                "print(results_df[['Model', 'RMSE', 'MAE']].to_string(index=False))\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize results\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "models = ['Ridge', 'Random Forest', 'LightGBM']\n",
                "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
                "\n",
                "# RMSE comparison\n",
                "ax1 = axes[0]\n",
                "rmse_means = [ridge_cv['RMSE_mean'], rf_cv['RMSE_mean'], lgb_cv['RMSE_mean']]\n",
                "rmse_stds = [ridge_cv['RMSE_std'], rf_cv['RMSE_std'], lgb_cv['RMSE_std']]\n",
                "bars1 = ax1.bar(models, rmse_means, yerr=rmse_stds, color=colors, \n",
                "                edgecolor='black', linewidth=1.2, capsize=5)\n",
                "ax1.set_ylabel('RMSE (%)')\n",
                "ax1.set_title('Cross-Validation RMSE Comparison')\n",
                "ax1.set_ylim(0, max(rmse_means) * 1.3)\n",
                "for bar, val in zip(bars1, rmse_means):\n",
                "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
                "             f'{val:.3f}', ha='center', va='bottom', fontsize=11)\n",
                "\n",
                "# MAE comparison\n",
                "ax2 = axes[1]\n",
                "mae_means = [ridge_cv['MAE_mean'], rf_cv['MAE_mean'], lgb_cv['MAE_mean']]\n",
                "mae_stds = [ridge_cv['MAE_std'], rf_cv['MAE_std'], lgb_cv['MAE_std']]\n",
                "bars2 = ax2.bar(models, mae_means, yerr=mae_stds, color=colors,\n",
                "                edgecolor='black', linewidth=1.2, capsize=5)\n",
                "ax2.set_ylabel('MAE (%)')\n",
                "ax2.set_title('Cross-Validation MAE Comparison')\n",
                "ax2.set_ylim(0, max(mae_means) * 1.3)\n",
                "for bar, val in zip(bars2, mae_means):\n",
                "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
                "             f'{val:.3f}', ha='center', va='bottom', fontsize=11)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(DATA_DIR / 'model_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nComparison plot saved to: {DATA_DIR / 'model_comparison.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 7: Save Best Model\n",
                "\n",
                "Identify and save the best-performing model based on RMSE."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify best model\n",
                "best_idx = results_df['RMSE_mean'].idxmin()\n",
                "best_model_name = results_df.loc[best_idx, 'Model']\n",
                "best_rmse = results_df.loc[best_idx, 'RMSE_mean']\n",
                "\n",
                "print(f\"Best model: {best_model_name}\")\n",
                "print(f\"RMSE: {best_rmse:.4f}%\")\n",
                "\n",
                "# Select corresponding trained model\n",
                "if 'Ridge' in best_model_name:\n",
                "    best_model = ridge_model\n",
                "elif 'Random Forest' in best_model_name:\n",
                "    best_model = rf_model\n",
                "else:\n",
                "    best_model = lgb_model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create models directory and save\n",
                "MODELS_DIR = Path.cwd().parent / \"models\"\n",
                "MODELS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "# Save best model\n",
                "model_filename = f\"best_model_{best_model_name.lower().replace(' ', '_')}.joblib\"\n",
                "save_model(best_model, str(MODELS_DIR / model_filename))\n",
                "print(f\"\\nBest model saved to: {MODELS_DIR / model_filename}\")\n",
                "\n",
                "# Also save all models for comparison\n",
                "save_model(ridge_model, str(MODELS_DIR / \"ridge_model.joblib\"))\n",
                "save_model(rf_model, str(MODELS_DIR / \"random_forest_model.joblib\"))\n",
                "save_model(lgb_model, str(MODELS_DIR / \"lightgbm_model.joblib\"))\n",
                "print(f\"\\nAll models saved to: {MODELS_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 8: Test Set Evaluation\n",
                "\n",
                "Final evaluation on held-out test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on test set\n",
                "y_pred_ridge = ridge_model.predict(X_test)\n",
                "y_pred_rf = rf_model.predict(X_test)\n",
                "y_pred_lgb = lgb_model.predict(X_test)\n",
                "\n",
                "# Calculate test metrics\n",
                "def calc_metrics(y_true, y_pred):\n",
                "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
                "    mae = np.mean(np.abs(y_true - y_pred))\n",
                "    return rmse, mae\n",
                "\n",
                "ridge_rmse, ridge_mae = calc_metrics(y_test, y_pred_ridge)\n",
                "rf_rmse, rf_mae = calc_metrics(y_test, y_pred_rf)\n",
                "lgb_rmse, lgb_mae = calc_metrics(y_test, y_pred_lgb)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"TEST SET PERFORMANCE\")\n",
                "print(\"=\"*50)\n",
                "print(f\"{'Model':<20} {'RMSE':>10} {'MAE':>10}\")\n",
                "print(\"-\"*50)\n",
                "print(f\"{'Ridge Regression':<20} {ridge_rmse:>10.4f} {ridge_mae:>10.4f}\")\n",
                "print(f\"{'Random Forest':<20} {rf_rmse:>10.4f} {rf_mae:>10.4f}\")\n",
                "print(f\"{'LightGBM':<20} {lgb_rmse:>10.4f} {lgb_mae:>10.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scatter plot: Predicted vs Actual for best model\n",
                "if 'Ridge' in best_model_name:\n",
                "    y_pred_best = y_pred_ridge\n",
                "elif 'Random Forest' in best_model_name:\n",
                "    y_pred_best = y_pred_rf\n",
                "else:\n",
                "    y_pred_best = y_pred_lgb\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 8))\n",
                "\n",
                "ax.scatter(y_test, y_pred_best, alpha=0.4, s=15, c='steelblue')\n",
                "ax.plot([4, 14], [4, 14], 'r--', linewidth=2, label='Perfect prediction')\n",
                "ax.plot([4, 14], [4.5, 14.5], 'k:', alpha=0.5, label='±0.5% bounds')\n",
                "ax.plot([4, 14], [3.5, 13.5], 'k:', alpha=0.5)\n",
                "\n",
                "ax.set_xlabel('Measured HbA1c (%)', fontsize=12)\n",
                "ax.set_ylabel('Predicted HbA1c (%)', fontsize=12)\n",
                "ax.set_title(f'Test Set: {best_model_name}\\nRMSE = {calc_metrics(y_test, y_pred_best)[0]:.3f}%', fontsize=14)\n",
                "ax.legend()\n",
                "ax.set_xlim(4, 14)\n",
                "ax.set_ylim(4, 14)\n",
                "ax.set_aspect('equal')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(DATA_DIR / 'best_model_predictions.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nPlot saved to: {DATA_DIR / 'best_model_predictions.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary\n",
                "\n",
                "This notebook demonstrated the complete ML training workflow for HbA1c estimation:\n",
                "\n",
                "1. **Loaded** cleaned NHANES glycemic data\n",
                "2. **Engineered features** including biomarkers, ratios, and mechanistic estimator predictions\n",
                "3. **Split data** with stratification by HbA1c clinical ranges\n",
                "4. **Trained** Ridge Regression, Random Forest, and LightGBM models\n",
                "5. **Cross-validated** all models with 10-fold CV\n",
                "6. **Compared** model performance and saved the best model\n",
                "\n",
                "### Key Findings\n",
                "\n",
                "- All ML models benefit from mechanistic estimator features (hybrid approach)\n",
                "- Gradient boosting (LightGBM) typically achieves best performance\n",
                "- Random Forest provides robust nonlinear predictions\n",
                "- Ridge regression serves as interpretable baseline\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "Continue to **Notebook 04: Evaluation** for comprehensive performance analysis including:\n",
                "- Bland-Altman analysis\n",
                "- Subgroup evaluation (anemia, age groups)\n",
                "- Lin's Concordance Correlation Coefficient"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}