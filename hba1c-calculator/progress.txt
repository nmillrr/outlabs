# Progress Log

## Learnings
(Patterns discovered during implementation)
- Use `python -m pytest` instead of `pytest` directly on Windows to avoid PATH issues
- Numpy arrays can be passed through the conversion functions for vectorized operations

---

## Iteration 1 - US-002: Implement Unit Conversion Utilities
- **What was implemented:**
  - `mg_dl_to_mmol_l()` - glucose mg/dL to mmol/L conversion
  - `mmol_l_to_mg_dl()` - glucose mmol/L to mg/dL conversion
  - `percent_to_mmol_mol()` - HbA1c NGSP (%) to IFCC (mmol/mol) conversion
  - `mmol_mol_to_percent()` - HbA1c IFCC (mmol/mol) to NGSP (%) conversion
- **Files changed:**
  - `hba1cE/utils.py` - Added all four conversion functions with docstrings
  - `tests/test_utils.py` - Created with 15 comprehensive tests
- **Learnings for future iterations:**
  - Conversion factors: glucose ÷18.018, HbA1c uses (NGSP - 2.15) × 10.929
  - Functions support both scalar and numpy array inputs
  - Clinical thresholds: 126 mg/dL ≈ 7.0 mmol/L, 6.5% HbA1c ≈ 48 mmol/mol
---

## Iteration 2 - US-003: Create NHANES Glycemic Download Module
- **What was implemented:**
  - `download_nhanes_glycemic(output_dir, cycles)` function in `hba1cE/data.py`
  - Complete file mappings for all NHANES cycles 2011-2018 (GHB, GLU, TRIGLY, HDL, CBC, DEMO)
  - Automatic `data/raw/` directory creation with Path.mkdir(parents=True)
  - Graceful error handling for URLError, HTTPError, and OSError
  - Skip existing files to avoid re-downloading
- **Files changed:**
  - `hba1cE/data.py` - Added download function with ~120 lines of implementation
- **Learnings for future iterations:**
  - NHANES file naming convention: `{DATA_TYPE}_{CYCLE_LETTER}.XPT` (e.g., GHB_J.XPT for 2017-2018)
  - NHANES base URL: https://wwwn.cdc.gov/Nchs/Nhanes/{cycle}/{filename}
  - Cycles use letter suffixes: G=2011-12, H=2013-14, I=2015-16, J=2017-18
---

## Iteration 3 - US-004: Implement XPT File Parser
- **What was implemented:**
  - `read_xpt(filepath)` function in `hba1cE/data.py`
  - Uses `pandas.read_sas(filepath, format="xport")` to read SAS transport files
  - Raises FileNotFoundError with informative message for missing files
  - Wraps pandas exceptions in ValueError with helpful context
- **Files changed:**
  - `hba1cE/data.py` - Added pandas import and read_xpt function (~35 lines)
  - `tests/test_data.py` - Created with 5 unit tests using mocking
- **Learnings for future iterations:**
  - Pandas `read_sas()` handles XPT format natively with `format="xport"` parameter
  - Pandas doesn't have `to_sas()` method - use mocking for tests or external libraries
  - Use `unittest.mock.patch` to mock pandas functions for predictable test behavior
---

## Iteration 4 - US-005: Create NHANES Glycemic Data Cleaning Pipeline
- **What was implemented:**
  - `clean_glycemic_data(ghb_df, glu_df, trigly_df, hdl_df, cbc_df, demo_df)` function in `hba1cE/data.py`
  - Merges 6 NHANES DataFrames on SEQN (sample ID) using inner join
  - Renames NHANES columns to standardized names (hba1c_percent, fpg_mgdl, tg_mgdl, hdl_mgdl, hgb_gdl, mcv_fl, age_years, sex)
  - Removes physiologic outliers (HbA1c < 3% or > 20%, FPG < 40 or > 600 mg/dL)
  - Returns only complete cases (rows without missing values)
- **Files changed:**
  - `hba1cE/data.py` - Added `clean_glycemic_data()` function (~85 lines)
  - `tests/test_data.py` - Added `TestCleanGlycemicData` class with 6 unit tests
- **Learnings for future iterations:**
  - NHANES column mappings: LBXGH=HbA1c, LBXGLU=FPG, LBXTR=TG, LBDHDD=HDL, LBXHGB=Hemoglobin, LBXMCVSI=MCV
  - Use `pd.DataFrame.merge()` with `how="inner"` for multi-dataset joins
  - Reset index after filtering to ensure sequential row indexing
---

## Iteration 5 - US-006: Generate Data Quality Report
- **What was implemented:**
  - `generate_quality_report(df, output_path)` function in `hba1cE/data.py`
  - Returns dict with record_count, stats (mean/SD), hba1c_distribution, fpg_distribution
  - Saves formatted text report to specified path
  - Calculates clinical distribution breakdowns for HbA1c (<5.7%, 5.7-6.4%, ≥6.5%)
  - Calculates clinical distribution breakdowns for FPG (<100, 100-125, ≥126 mg/dL)
- **Files changed:**
  - `hba1cE/data.py` - Added `generate_quality_report()` function (~115 lines)
  - `tests/test_data.py` - Added `TestGenerateQualityReport` class with 6 unit tests
- **Learnings for future iterations:**
  - Clinical thresholds: HbA1c 5.7% (prediabetes), 6.5% (diabetes); FPG 100 mg/dL, 126 mg/dL
  - Use Path.parent.mkdir(parents=True, exist_ok=True) to ensure output directory exists
  - Return both dict (for programmatic use) and save text file (for human review)
---

## Iteration 6 - US-007: Create Data Sourcing Notebook
- **What was implemented:**
  - `notebooks/01_data_sourcing.ipynb` - Full Jupyter notebook demonstrating NHANES data pipeline
  - Step 1: Downloading NHANES XPT files using `download_nhanes_glycemic()`
  - Step 2: Parsing XPT files with `read_xpt()` function
  - Step 3: Cleaning and merging data with `clean_glycemic_data()`
  - Step 4: Generating quality report with `generate_quality_report()`
  - Step 5: Visualizations - HbA1c vs FPG scatter, distributions, correlation matrix
- **Files changed:**
  - `notebooks/01_data_sourcing.ipynb` - Created new notebook (~350 lines)
- **Learnings for future iterations:**
  - Use `sys.path.insert(0, str(Path.cwd().parent))` in notebooks to import from parent package
  - `plt.style.use('seaborn-v0_8-whitegrid')` for modern seaborn style (v0.12+ naming)
  - Save cleaned data to `data/processed/` for use in subsequent notebooks
  - Clinical thresholds: HbA1c 5.7%/6.5%, FPG 100/126 mg/dL - show as reference lines
---

## Iteration 7 - US-008: Implement ADAG Equation (Inverted)
- **What was implemented:**
  - `calc_hba1c_adag(fpg_mgdl)` function in `hba1cE/models.py`
  - Formula: eHbA1c = (FPG + 46.7) / 28.7
  - Supports both scalar float and numpy array inputs
  - Input validation: rejects negative, NaN, and FPG < 40 mg/dL
  - Full docstring with Nathan et al. (2008) reference
- **Files changed:**
  - `hba1cE/models.py` - Added numpy/math imports and calc_hba1c_adag function (~60 lines)
- **Learnings for future iterations:**
  - ADAG equation from Nathan et al. 2008: eAG = 28.7 × HbA1c - 46.7 (inverted for HbA1c estimation)
  - FPG=126 → eHbA1c ≈ 6.0%, FPG=154 → eHbA1c ≈ 7.0% (matches expected clinical values)
  - Use `math.isnan()` for scalar NaN checks, `np.any(np.isnan())` for arrays
---

## Iteration 8 - US-009: Test ADAG Against Expected Values
- **What was implemented:**
  - 8 comprehensive unit tests in `tests/test_models.py` for `calc_hba1c_adag()`
  - Test cases: FPG=126 → ~6.0%, FPG=154 → ~7.0%
  - Invalid input tests: negative values, NaN values, FPG < 40 mg/dL
  - Array input tests: valid arrays, arrays with NaN, arrays with negatives
- **Files changed:**
  - `tests/test_models.py` - Added `TestCalcHba1cAdag` class with 8 unit tests
- **Learnings for future iterations:**
  - Use `pytest.raises(ValueError, match="pattern")` for exception testing with message matching
  - ADAG formula verified: (126 + 46.7) / 28.7 ≈ 6.02%, (154 + 46.7) / 28.7 ≈ 6.99%
  - Tests confirm both scalar and numpy array functionality works correctly
---

## Iteration 9 - US-010: Implement Glycation Kinetics Model
- **What was implemented:**
  - `calc_hba1c_kinetic(fpg_mgdl, hgb_gdl=14.0, rbc_lifespan_days=120, k=4.5e-5)` in `hba1cE/models.py`
  - Formula: HbA1c = baseline + k × [Glucose] × RBC_lifespan × (Hgb_ref / Hgb)
  - Anemia correction: lower hemoglobin → higher HbA1c estimate
  - RBC lifespan adjustment: shorter lifespan → lower HbA1c
  - Baseline non-glycemic HbA1c of 4.0%
  - 11 comprehensive unit tests in `tests/test_models.py`
- **Files changed:**
  - `hba1cE/models.py` - Added `calc_hba1c_kinetic()` function (~110 lines)
  - `tests/test_models.py` - Added `TestCalcHba1cKinetic` class with 11 tests
- **Learnings for future iterations:**
  - Glycation kinetics: HbA1c = baseline + k × glucose × time × (1/Hgb)
  - Anemia increases HbA1c at same glucose (less hemoglobin to distribute glycation)
  - Shorter RBC lifespan (hemolysis) decreases HbA1c (less time for glycation)
  - Default k = 4.5e-5 gives reasonable values: FPG=100 → ~4.5%, FPG=200 → ~5.1%
  - Output always in range 3-20% for valid inputs
---

## Iteration 10 - US-011: Implement Multi-Linear Regression Estimator
- **What was implemented:**
  - `calc_hba1c_regression(fpg_mgdl, age_years, tg_mgdl, hdl_mgdl, hgb_gdl, coefficients=None)` in `hba1cE/models.py`
  - `fit_regression_coefficients(df)` to fit coefficients from NHANES data using sklearn
  - Formula: eHbA1c = β₀ + β₁×FPG + β₂×Age + β₃×TG + β₄×HDL + β₅×Hgb
  - Default placeholder coefficients for use before fitting
  - Comprehensive input validation for both scalar and array inputs
  - 14 new unit tests (11 for regression function, 3 for coefficient fitting)
- **Files changed:**
  - `hba1cE/models.py` - Added DEFAULT_REGRESSION_COEFFICIENTS dict and two new functions (~180 lines)
  - `tests/test_models.py` - Added TestCalcHba1cRegression and TestFitRegressionCoefficients classes
- **Learnings for future iterations:**
  - Multi-linear regression formula: HbA1c = intercept + β_fpg×FPG + β_age×Age + β_tg×TG + β_hdl×HDL + β_hgb×Hgb
  - Default coefficients: intercept=3.5, fpg=0.02, age=0.008, tg=0.001, hdl=-0.005, hgb=-0.05
  - sklearn LinearRegression fits coefficients via model.coef_ and model.intercept_
  - Coefficients can be passed to calc_hba1c_regression() for custom-fitted models
  - Input validation mirrors other model functions (negative, NaN, physiological range checks)
---

## Iteration 11 - US-012: Create Estimator Comparison Notebook
- **What was implemented:**
  - `notebooks/02_estimator_comparison.ipynb` - Jupyter notebook comparing all three mechanistic estimators
  - Loads cleaned NHANES data from `data/processed/nhanes_glycemic_cleaned.csv`
  - Applies ADAG, Glycation Kinetics, and Regression estimators to full dataset
  - Fits regression coefficients on 70% training split
  - Calculates performance metrics: RMSE, MAE, Bias, Pearson r, % within ±0.5%/±1.0%
  - Generates scatter plots (estimated vs measured) for all three methods
  - Creates Bland-Altman plots to assess bias and limits of agreement
  - Includes error distribution histogram overlay
  - Stratified analysis by HbA1c ranges (normal, prediabetes, diabetes)
  - Comprehensive interpretation section covering pros/cons of each method
- **Files changed:**
  - `notebooks/02_estimator_comparison.ipynb` - Created new notebook (~400 lines)
- **Learnings for future iterations:**
  - All mechanistic estimators struggle in the diabetes range (HbA1c ≥6.5%)
  - Multi-marker regression approach uses fitted coefficients that are dataset-specific
  - Bland-Altman plots reveal systematic bias patterns across the HbA1c range
  - Clinical strata for evaluation: <5.7% (normal), 5.7-6.4% (prediabetes), ≥6.5% (diabetes)
---

## Iteration 12 - US-013: Create Feature Engineering Module
- **What was implemented:**
  - `create_features(df)` function in `hba1cE/train.py`
  - Creates 11 features total for ML training
  - Raw biomarker features: fpg_mgdl, tg_mgdl, hdl_mgdl, age_years, hgb_gdl, mcv_fl
  - Ratio features: tg_hdl_ratio, fpg_age_interaction
  - Mechanistic estimator predictions: adag_estimate, kinetic_estimate, regression_estimate
  - Returns tuple of (X, feature_names) for sklearn compatibility
  - Comprehensive input validation for required columns
  - 6 unit tests covering functionality, ratios, and error handling
- **Files changed:**
  - `hba1cE/train.py` - Created new module with create_features function (~85 lines)
  - `tests/test_train.py` - Created with 6 unit tests for create_features
- **Learnings for future iterations:**
  - Feature engineering includes: raw biomarkers + ratio features + mechanistic estimator predictions
  - TG/HDL ratio is a good predictor of insulin resistance
  - Mechanistic estimator predictions can be used as features for hybrid ML approach
  - Use `np.column_stack()` to combine feature arrays into single matrix
---

## Iteration 13 - US-014: Implement Train/Test Split with Stratification
- **What was implemented:**
  - `stratified_split(df, test_size=0.3, random_state=42)` function in `hba1cE/train.py`
  - Stratifies by 5 HbA1c clinical ranges: <5.7%, 5.7-6.4%, 6.5-8%, 8-10%, >10%
  - Uses sklearn's `train_test_split` with `stratify` parameter
  - Returns X_train, X_test, y_train, y_test tuple
  - Input validation for missing hba1c_percent column
  - Checks that all strata have at least 2 samples
  - 7 new unit tests covering functionality, stratification, reproducibility
- **Files changed:**
  - `hba1cE/train.py` - Added `stratified_split()` function (~70 lines) and sklearn import
  - `tests/test_train.py` - Added `TestStratifiedSplit` class with 7 unit tests
- **Learnings for future iterations:**
  - Use `pd.cut()` with custom bins and labels for stratification grouping
  - sklearn's `train_test_split` accepts `stratify` parameter for balanced splits
  - Stratification bins: [0, 5.7, 6.5, 8.0, 10.0, inf] cover all clinical ranges
  - Need at least 2 samples per stratum for valid stratified split
  - Test fixture pattern useful for creating sample data across all strata
---

## Iteration 14 - US-015: Train Ridge Regression Baseline
- **What was implemented:**
  - `train_ridge(X_train, y_train, alpha=1.0)` function in `hba1cE/train.py`
  - `save_model(model, filepath)` function using joblib for model persistence
  - Ridge model returns fitted sklearn Ridge regressor with L2 regularization
  - Input validation for X/y shape compatibility
  - save_model creates parent directories if they don't exist
  - 5 new tests for train_ridge, 3 new tests for save_model
- **Files changed:**
  - `hba1cE/train.py` - Added Ridge import, joblib import, and two new functions (~70 lines)
  - `tests/test_train.py` - Added TestTrainRidge (5 tests) and TestSaveModel (3 tests) classes
- **Learnings for future iterations:**
  - sklearn Ridge model is simple to train: `Ridge(alpha=alpha).fit(X, y)`
  - joblib is preferred over pickle for sklearn models (handles numpy arrays better)
  - Higher alpha parameter shrinks coefficients more (useful for regularization tuning)
  - Use Path.parent.mkdir(parents=True, exist_ok=True) to ensure save directories exist
  - Ridge model stores coefficients in .coef_ and intercept in .intercept_
---

## Iteration 15 - US-016: Train Random Forest Model
- **What was implemented:**
  - `train_random_forest(X_train, y_train, n_estimators=200)` function in `hba1cE/train.py`
  - Returns fitted RandomForestRegressor with configurable n_estimators
  - Input validation for X/y shape compatibility
  - Uses fixed random_state=42 for reproducibility
  - 5 comprehensive unit tests (basic training, prediction, custom estimators, shape validation, reproducibility)
- **Files changed:**
  - `hba1cE/train.py` - Added RandomForestRegressor import and train_random_forest function (~40 lines)
  - `tests/test_train.py` - Added TestTrainRandomForest class with 5 tests
- **Learnings for future iterations:**
  - RandomForestRegressor is an ensemble that averages multiple decision tree predictions
  - Use random_state parameter for reproducibility in model training
  - Feature importance available via model.feature_importances_ after training
  - Default n_estimators=200 balances performance with computation time
---


## Iteration 16 - US-017: Train LightGBM Model (INCOMPLETE)
- **What was implemented:**
  - `train_lightgbm(X_train, y_train, X_val, y_val, n_estimators=1000, early_stopping_rounds=20)` in `hba1cE/train.py`
  - Lazy import of LGBMRegressor to avoid module-level import errors
  - Early stopping via lightgbm.early_stopping callback
  - Input validation for X/y shape compatibility
  - 6 unit tests in `tests/test_train.py` (TestTrainLightGBM class)
- **Files changed:**
  - `hba1cE/train.py` - Added train_lightgbm function (~70 lines)
  - `tests/test_train.py` - Added TestTrainLightGBM class with 6 tests
- **What went wrong:**
  - LightGBM requires libomp (OpenMP) system dependency which is not installed
  - Error: `OSError: dlopen lib_lightgbm.dylib: Library not loaded: @rpath/libomp.dylib`
  - Homebrew install of libomp failed due to network issues
  - All other 25 train tests pass, only LightGBM-specific tests fail
- **Learnings for future iterations:**
  - LightGBM on macOS requires: `brew install libomp` before running tests
  - Use lazy imports for optional dependencies to avoid breaking module imports
  - The code is correctly implemented, just needs system dependency
  - To fix: Run `brew install libomp` then re-run tests
---

## Iteration 17 - US-017: Train LightGBM Model (COMPLETE)
- **What was implemented:**
  - `train_lightgbm(X_train, y_train, X_val, y_val, n_estimators=1000, early_stopping_rounds=20)` in `hba1cE/train.py`
  - Lazy import of LGBMRegressor to avoid module-level import errors
  - Early stopping via lightgbm.early_stopping callback
  - Input validation for X/y shape compatibility
  - 6 unit tests in `tests/test_train.py` (TestTrainLightGBM class)
- **Files changed:**
  - `hba1cE/train.py` - train_lightgbm function (~70 lines)
  - `tests/test_train.py` - TestTrainLightGBM class with 6 tests
- **Resolution:**
  - libomp dependency was resolved (now installed on system)
  - All 6 LightGBM tests pass
  - Full test suite: 96 passed, 0 failed
- **Learnings for future iterations:**
  - LightGBM on macOS requires libomp (OpenMP) system dependency
  - Use lazy imports for optional dependencies to avoid breaking module imports
  - early_stopping callback is the modern way to implement early stopping in LightGBM
---

## Iteration 18 - US-018: Implement Cross-Validation Wrapper
- **What was implemented:**
  - `cross_validate_model(model, X, y, n_splits=10)` function in `hba1cE/train.py`
  - Uses sklearn's KFold for k-fold cross-validation with shuffle
  - Clones model for each fold to ensure fresh instance
  - Calculates RMSE and MAE for each fold, returns mean and std
  - Input validation for shape compatibility and n_splits >= 2
  - 7 comprehensive unit tests in `tests/test_train.py` (TestCrossValidateModel class)
- **Files changed:**
  - `hba1cE/train.py` - Added KFold and clone imports, cross_validate_model function (~75 lines)
  - `tests/test_train.py` - Added TestCrossValidateModel class with 7 tests
- **Learnings for future iterations:**
  - Use sklearn's `clone()` to get fresh model instances for each CV fold
  - KFold with shuffle=True and random_state ensures reproducible splits
  - Return dict format allows easy access to metrics: RMSE_mean, RMSE_std, MAE_mean, MAE_std
  - All 103 tests pass after implementation
---

## Iteration 19 - US-019: Create Model Training Notebook
- **What was implemented:**
  - `notebooks/03_model_training.ipynb` - Complete ML training workflow notebook
  - Step 1: Loading cleaned NHANES data from `data/processed/nhanes_glycemic_cleaned.csv`
  - Step 2: Feature engineering using `create_features()` (11 features)
  - Step 3: Stratified train/test split by HbA1c clinical ranges
  - Step 4: Training Ridge, Random Forest, and LightGBM models
  - Step 5: 10-fold cross-validation for all models
  - Step 6: Results comparison table with formatted RMSE/MAE metrics
  - Step 7: Bar chart visualization of CV results
  - Step 8: Saving best model to `models/` directory
  - Step 9: Test set evaluation with scatter plot
- **Files changed:**
  - `notebooks/03_model_training.ipynb` - Created new notebook (~400 lines)
- **Learnings for future iterations:**
  - Use `plt.style.use('seaborn-v0_8-whitegrid')` for modern seaborn style
  - Create validation set from training data for LightGBM early stopping
  - Use simpler model configs (fewer estimators) for CV to reduce runtime
  - Save all models, not just best, for later comparison
  - All 103 tests pass after implementation
---


## Iteration 20 - US-021: Implement Lin's CCC
- **What was implemented:**
  - `lins_ccc(y_true, y_pred)` function in `hba1cE/evaluate.py`
  - Formula: CCC = 2 * cov(X,Y) / (var(X) + var(Y) + (mean_X - mean_Y)^2)
  - Returns CCC value in range [-1, 1]
  - Handles edge case of constant identical arrays (returns 1.0)
  - Fixed validation order: length-mismatch check now runs before min-elements check
  - 9 comprehensive unit tests in `tests/test_evaluate.py` (TestLinsCCC class)
- **Files changed:**
  - `hba1cE/evaluate.py` - Fixed validation order in lins_ccc function
- **Learnings for future iterations:**
  - Validation order matters: check length mismatch before minimum element count
  - Lin's CCC combines precision (Pearson r) and accuracy (bias correction)
  - CCC < Pearson r when there is systematic bias between measurements
  - Use `python3` not `python` on this system
  - All 20 evaluate tests pass
---

## Iteration 21 - US-022: Create Comprehensive Evaluation Function
- **What was implemented:**
  - `evaluate_model(y_true, y_pred, model_name)` function in `hba1cE/evaluate.py`
  - Returns dict with: model_name, rmse, mae, bias, r_pearson, lin_ccc, ba_stats, pct_within_0_5
  - RMSE and MAE computed from prediction errors
  - Pearson r via scipy.stats.pearsonr
  - Reuses existing `lins_ccc` and `bland_altman_stats` functions
  - pct_within_0_5 = percentage of predictions within ±0.5% of measured HbA1c
  - Comprehensive input validation (length mismatch, NaN, min 2 elements)
  - 10 unit tests in `tests/test_evaluate.py` (TestEvaluateModel class)
- **Files changed:**
  - `hba1cE/evaluate.py` - Added `evaluate_model()` function (~90 lines)
  - `tests/test_evaluate.py` - Added TestEvaluateModel class with 10 tests
- **Learnings for future iterations:**
  - Reuse existing metric functions (lins_ccc, bland_altman_stats) inside composite functions
  - scipy.stats.pearsonr returns (r, p_value) tuple
  - pct_within_0_5 is a clinically relevant metric: % of estimates within ±0.5% HbA1c
  - All 30 evaluate tests pass
---

## Iteration 22 - US-023: Implement HbA1c-Stratified Evaluation
- **What was implemented:**
  - `evaluate_by_hba1c_strata(y_true, y_pred, hba1c_values)` function in `hba1cE/evaluate.py`
  - Stratifies by 3 clinical ranges: <5.7% (normal), 5.7-6.4% (prediabetes), ≥6.5% (diabetes)
  - Returns metrics dict for each stratum using `evaluate_model()`, or None if <2 samples
  - Input validation for length mismatch, NaN, and empty inputs
  - 8 unit tests in `tests/test_evaluate.py` (TestEvaluateByHba1cStrata class)
- **Files changed:**
  - `hba1cE/evaluate.py` - Already had evaluate_by_hba1c_strata implemented
  - `tests/test_evaluate.py` - Already had 8 tests for the function
  - `PRD.md` - Marked US-023 acceptance criteria as complete
- **Learnings for future iterations:**
  - Function was already implemented from a previous iteration but PRD was not updated
  - Always check if code already exists before implementing
  - All 38 evaluate tests pass
---

## Iteration 23 - US-024: Implement Subgroup Evaluation (anemia, age)
- **What was implemented:**
  - `define_subgroups(df)` function in `hba1cE/evaluate.py`
    - Creates `anemia` column: Hgb < 12 g/dL (female, sex=2) or < 13 g/dL (male, sex=1)
    - Creates `age_group` column: <40, 40-60, >60 years
    - Creates `mcv_group` column: low (<80 fL), normal (80-100 fL), high (>100 fL)
    - Returns a copy (does not modify original DataFrame)
  - `evaluate_by_subgroup(y_true, y_pred, df, subgroup_col, subgroup_values)` function
    - Evaluates model performance for each subgroup value using `evaluate_model()`
    - Returns None for subgroups with < 2 samples
    - Handles both boolean and string subgroup values
  - 7 tests for `define_subgroups` (anemia detection, age groups, MCV groups, missing columns)
  - 7 tests for `evaluate_by_subgroup` (metrics per subgroup, sparse subgroups, validation errors)
- **Files changed:**
  - `hba1cE/evaluate.py` - Added `define_subgroups()` and `evaluate_by_subgroup()` functions (~140 lines)
  - `tests/test_evaluate.py` - Added `TestDefineSubgroups` (7 tests) and `TestEvaluateBySubgroup` (7 tests)
  - `PRD.md` - Marked US-024 acceptance criteria as complete
- **Learnings for future iterations:**
  - NHANES sex coding: 1 = male, 2 = female
  - Anemia thresholds: Hgb < 12 g/dL (female), < 13 g/dL (male)
  - Use `np.select()` for multi-condition categorical assignment in DataFrames
  - `evaluate_by_subgroup` is generic - works with any subgroup column, not just predefined ones
  - All 52 evaluate tests pass
---

## Iteration 24 - US-025: Implement Bootstrap Confidence Intervals
- **What was implemented:**
  - `bootstrap_ci(y_true, y_pred, metric_func, n_bootstrap=2000, confidence_level=0.95, random_state=42)` in `hba1cE/evaluate.py`
  - Resamples y_true and y_pred with replacement n_bootstrap times
  - Computes metric_func on each resample and returns percentile-based CI
  - Returns (lower, upper, mean) tuple
  - 8 unit tests in `tests/test_evaluate.py` (TestBootstrapCI class)
- **Files changed:**
  - `hba1cE/evaluate.py` - Already had bootstrap_ci implemented
  - `tests/test_evaluate.py` - Already had 8 tests for bootstrap_ci
  - `PRD.md` - Marked US-025 acceptance criteria as complete
- **Learnings for future iterations:**
  - Function was already implemented from a previous iteration but PRD was not updated
  - Always check if code already exists before implementing
  - All 60 evaluate tests pass
---
