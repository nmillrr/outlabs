{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03 — Model Training\n",
                "\n",
                "This notebook trains three ML models on NHANES kidney-function data and compares\n",
                "their performance via 10-fold cross-validation.  The models are:\n",
                "\n",
                "| Model | Type | Notes |\n",
                "|-------|------|-------|\n",
                "| **Ridge** | Linear (L2) | Simple baseline |\n",
                "| **Random Forest** | Ensemble (bagging) | Captures non-linear patterns |\n",
                "| **LightGBM** | Gradient boosting | Best expected performance |\n",
                "\n",
                "The best model (lowest CV RMSE) is saved to `models/` for downstream use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import warnings\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib\n",
                "matplotlib.use(\"Agg\")\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Ensure the project root is on sys.path so that `eGFR` can be imported\n",
                "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
                "if PROJECT_ROOT not in sys.path:\n",
                "    sys.path.insert(0, PROJECT_ROOT)\n",
                "\n",
                "from eGFR.data import read_xpt, clean_kidney_data\n",
                "from eGFR.train import (\n",
                "    create_features,\n",
                "    stratified_split,\n",
                "    train_ridge,\n",
                "    train_random_forest,\n",
                "    train_lightgbm,\n",
                "    cross_validate_model,\n",
                "    save_model,\n",
                ")\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
                "print(\"Imports OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1 — Load Data\n",
                "\n",
                "If real NHANES XPT files are available in `data/raw/` we use them.  Otherwise we\n",
                "fall back to a synthetic dataset that mirrors the NHANES schema so that this\n",
                "notebook can execute in any environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "RAW_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
                "\n",
                "\n",
                "def _try_load_nhanes():\n",
                "    \"\"\"Attempt to load real NHANES data from data/raw/.\"\"\"\n",
                "    cycles_to_try = [\n",
                "        (\"2017-2018\", \"_J\"),\n",
                "        (\"2015-2016\", \"_I\"),\n",
                "        (\"2013-2014\", \"_H\"),\n",
                "    ]\n",
                "    for cycle, suffix in cycles_to_try:\n",
                "        biopro_path = os.path.join(RAW_DIR, f\"BIOPRO{suffix}.XPT\")\n",
                "        demo_path = os.path.join(RAW_DIR, f\"DEMO{suffix}.XPT\")\n",
                "        bmx_path = os.path.join(RAW_DIR, f\"BMX{suffix}.XPT\")\n",
                "        if all(os.path.isfile(p) for p in [biopro_path, demo_path, bmx_path]):\n",
                "            try:\n",
                "                print(f\"Loading real NHANES data for cycle {cycle}\")\n",
                "                biopro = read_xpt(biopro_path)\n",
                "                demo = read_xpt(demo_path)\n",
                "                bmx = read_xpt(bmx_path)\n",
                "                return clean_kidney_data(biopro, demo, bmx)\n",
                "            except (ValueError, Exception) as exc:\n",
                "                print(f\"  Could not parse {cycle} XPT files: {exc}\")\n",
                "                continue\n",
                "    return None\n",
                "\n",
                "\n",
                "def _generate_synthetic(n=2000, seed=42):\n",
                "    \"\"\"Generate a synthetic clinical dataset mimicking NHANES schema.\"\"\"\n",
                "    rng = np.random.default_rng(seed)\n",
                "    ages = rng.integers(18, 85, size=n).astype(float)\n",
                "    sexes = rng.choice([1, 2], size=n)  # NHANES coding: 1=M, 2=F\n",
                "    cr = np.exp(rng.normal(np.log(1.0), 0.35, size=n)).clip(0.3, 12.0)\n",
                "    weights = rng.normal(80, 15, size=n).clip(40, 160)\n",
                "    heights = rng.normal(170, 10, size=n).clip(140, 210)\n",
                "\n",
                "    df = pd.DataFrame({\n",
                "        \"cr_mgdl\": cr,\n",
                "        \"age_years\": ages,\n",
                "        \"sex\": sexes,\n",
                "        \"weight_kg\": weights,\n",
                "        \"height_cm\": heights,\n",
                "    })\n",
                "    print(f\"Using synthetic dataset ({n} samples)\")\n",
                "    return df\n",
                "\n",
                "\n",
                "df = _try_load_nhanes()\n",
                "if df is None:\n",
                "    df = _generate_synthetic()\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2 — Feature Engineering & Stratified Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = stratified_split(df, test_size=0.3)\n",
                "\n",
                "print(f\"Training set : {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
                "print(f\"Test set     : {X_test.shape[0]:,} samples\")\n",
                "print(f\"\\nFeature columns: {list(X_train.columns)}\")\n",
                "print(f\"\\ny target (CKD-EPI 2021 eGFR) — train mean: {y_train.mean():.1f}, \"\n",
                "      f\"test mean: {y_test.mean():.1f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3 — Train Models\n",
                "\n",
                "We train **Ridge**, **Random Forest**, and **LightGBM** on the training split."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----- Ridge -----\n",
                "ridge_model = train_ridge(X_train, y_train, alpha=1.0)\n",
                "print(\"Ridge regression trained.\")\n",
                "\n",
                "# ----- Random Forest -----\n",
                "rf_model = train_random_forest(X_train, y_train, n_estimators=200)\n",
                "print(\"Random Forest trained (200 trees).\")\n",
                "\n",
                "# ----- LightGBM (needs a validation set for early stopping) -----\n",
                "# We use the held-out test set as the early-stopping validation set.\n",
                "lgb_model = train_lightgbm(X_train, y_train, X_test, y_test)\n",
                "print(\"LightGBM trained with early stopping.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4 — Cross-Validation Comparison\n",
                "\n",
                "We evaluate each model using 10-fold CV on the **full feature matrix** to get\n",
                "unbiased performance estimates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build full feature matrix for CV\n",
                "X_full, feature_names = create_features(df)\n",
                "y_full = X_full[\"egfr_ckd_epi_2021\"].copy()\n",
                "valid = y_full.notna()\n",
                "X_full = X_full.loc[valid]\n",
                "y_full = y_full.loc[valid]\n",
                "\n",
                "from sklearn.linear_model import Ridge\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "models_for_cv = {\n",
                "    \"Ridge\": Ridge(alpha=1.0),\n",
                "    \"Random Forest\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
                "}\n",
                "\n",
                "cv_results = {}\n",
                "\n",
                "for name, model in models_for_cv.items():\n",
                "    print(f\"Running 10-fold CV for {name}...\")\n",
                "    cv_results[name] = cross_validate_model(model, X_full, y_full, n_splits=10)\n",
                "\n",
                "# LightGBM cannot be cloned trivially via sklearn.base.clone because of\n",
                "# early stopping; we run CV manually with a fresh LGBMRegressor each fold.\n",
                "from lightgbm import LGBMRegressor\n",
                "\n",
                "print(\"Running 10-fold CV for LightGBM...\")\n",
                "lgb_base = LGBMRegressor(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.05,\n",
                "    random_state=42,\n",
                "    verbosity=-1,\n",
                ")\n",
                "cv_results[\"LightGBM\"] = cross_validate_model(lgb_base, X_full, y_full, n_splits=10)\n",
                "\n",
                "print(\"\\nCross-validation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build comparison table\n",
                "rows = []\n",
                "for name, metrics in cv_results.items():\n",
                "    rows.append({\n",
                "        \"Model\": name,\n",
                "        \"RMSE (mean)\": f\"{metrics['RMSE_mean']:.2f}\",\n",
                "        \"RMSE (std)\": f\"{metrics['RMSE_std']:.2f}\",\n",
                "        \"MAE (mean)\": f\"{metrics['MAE_mean']:.2f}\",\n",
                "        \"MAE (std)\": f\"{metrics['MAE_std']:.2f}\",\n",
                "    })\n",
                "\n",
                "cv_table = pd.DataFrame(rows).set_index(\"Model\")\n",
                "print(\"\\n=== 10-Fold Cross-Validation Results ===\")\n",
                "print(cv_table.to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5 — Select & Save Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Determine best model by lowest CV RMSE\n",
                "best_name = min(cv_results, key=lambda n: cv_results[n][\"RMSE_mean\"])\n",
                "best_rmse = cv_results[best_name][\"RMSE_mean\"]\n",
                "print(f\"Best model: {best_name} (CV RMSE = {best_rmse:.2f})\")\n",
                "\n",
                "# Map name -> fitted model object\n",
                "trained_models = {\n",
                "    \"Ridge\": ridge_model,\n",
                "    \"Random Forest\": rf_model,\n",
                "    \"LightGBM\": lgb_model,\n",
                "}\n",
                "best_model = trained_models[best_name]\n",
                "\n",
                "# Save best model\n",
                "MODEL_DIR = os.path.join(PROJECT_ROOT, \"models\")\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                "best_path = os.path.join(MODEL_DIR, \"best_model.joblib\")\n",
                "save_model(best_model, best_path)\n",
                "print(f\"Best model saved to: {best_path}\")\n",
                "\n",
                "# Also save all models individually for reference\n",
                "for name, model in trained_models.items():\n",
                "    slug = name.lower().replace(\" \", \"_\")\n",
                "    path = os.path.join(MODEL_DIR, f\"{slug}.joblib\")\n",
                "    save_model(model, path)\n",
                "    print(f\"  {name} -> {path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6 — Test-Set Predictions (Quick Sanity Check)\n",
                "\n",
                "We generate predictions on the held-out test set and show a scatter plot for the\n",
                "best model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
                "\n",
                "y_pred_test = best_model.predict(X_test)\n",
                "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
                "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
                "r2_test = r2_score(y_test, y_pred_test)\n",
                "\n",
                "print(f\"{best_name} — Test-set performance:\")\n",
                "print(f\"  RMSE : {rmse_test:.2f}\")\n",
                "print(f\"  MAE  : {mae_test:.2f}\")\n",
                "print(f\"  R2   : {r2_test:.4f}\")\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(6, 6))\n",
                "ax.scatter(y_test, y_pred_test, alpha=0.3, s=10, edgecolors=\"none\")\n",
                "lims = [0, max(y_test.max(), np.max(y_pred_test)) * 1.05]\n",
                "ax.plot(lims, lims, \"--\", color=\"red\", linewidth=1, label=\"Identity\")\n",
                "ax.set_xlabel(\"Actual eGFR (CKD-EPI 2021)\")\n",
                "ax.set_ylabel(\"Predicted eGFR\")\n",
                "ax.set_title(f\"{best_name} — Predicted vs Actual\")\n",
                "ax.legend()\n",
                "ax.set_xlim(lims)\n",
                "ax.set_ylim(lims)\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(PROJECT_ROOT, \"models\", \"best_model_scatter.png\"), dpi=150)\n",
                "plt.show()\n",
                "print(\"Done.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "- **Ridge**, **Random Forest**, and **LightGBM** models were trained on the\n",
                "  available dataset.\n",
                "- 10-fold cross-validation was used to compare model performance.\n",
                "- The best model (by CV RMSE) was saved to `models/best_model.joblib`.\n",
                "- All individual models were also saved to `models/` for reference.\n",
                "\n",
                "> **Note:** When using synthetic data, the models learn to reproduce the CKD-EPI\n",
                "> 2021 equation from the engineered features.  True model utility will be\n",
                "> assessed when real NHANES data with external measured-GFR validation is\n",
                "> available (see notebooks 04 and 05)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}